<questions>
1. How should the `RecipeVersion` steps be stored to allow for potential future step-by-step metadata while ensuring data integrity in MariaDB?

Recommendation: Store steps as a `JSON` column. Use the `JSON_VALID()` constraint to ensure the stored text blocks or structured objects (e.g., `[{"text": "...", "order": 1}]`) maintain a valid format, allowing for schema-less expansion without losing validation.

2. Should the `avoid_list` be a many-to-many relationship with a global `IngredientRegistry` or a `JSON` column on the `UserPreference`?

Recommendation: Use a standard many-to-many relationship table. While MariaDB supports `JSON`, a relational table ensures better referential integrity and faster JOIN performance when filtering recipes based on user exclusions compared to searching inside a JSON blob.

3. How will the `Recipe` "current" pointer and `RecipeVersion` immutability handle the "Undo" functionality in a relational way?

Recommendation: The `Recipe` table should include a `current_version_id` foreign key. To implement "Undo", update this pointer to the `parent_version_id` found on the current `RecipeVersion`. Ensure `ON DELETE CASCADE` is carefully managed to prevent accidental version loss.

4. What is the most efficient way to implement the full-text search for recipes and ingredients in MariaDB?

Recommendation: Use MariaDB `FULLTEXT` indexes on denormalized search columns. Create a dedicated `search_text` column in the `Recipe` or `RecipeVersion` table that concatenates the title and ingredient names, and update it via Application-layer logic or triggers for P95 performance.

5. How should `RecipeIngredient` quantities be stored to support high-precision scaling and unit conversion in MariaDB?

Recommendation: Use the `DECIMAL` (or `NUMERIC`) data type for quantities. Unlike `FLOAT` or `DOUBLE`, `DECIMAL` provides exact numeric representation, which is critical for scaling recipe ingredients and calculating calories without accumulating floating-point rounding errors.

6. Should the `substitutions` log be a dedicated table or a `JSON` column within `RecipeVersion`?

Recommendation: Use a dedicated `substitutions` table. This allows for straightforward relational queries to track how often certain ingredients are swapped, which is more efficient for analytics than parsing JSON data across all versions.

7. How should the 90-day retention for the `Events` table be managed to prevent performance degradation in MariaDB?

Recommendation: Use a Symfony console command to perform range-based deletes. For very high volumes, consider MariaDB Table Partitioning by `RANGE` on the `created_at` timestamp to allow for near-instant cleanup of old data by dropping partitions.

8. How will the `IngredientRegistry` be populated and managed to ensure consistent normalization?

Recommendation: Implement a dynamic registry where new ingredients are added as users enter them. Use a `is_verified` flag (TINYINT) to distinguish between user-generated content and normalized entries managed by the Unit Registry system.

9. What is the lifecycle and cleanup strategy for `draft_content` and `pending_recipe` records to keep the database lean?

Recommendation: Assign an `expires_at` (DATETIME) to these records. A scheduled Symfony command should run periodically to delete records where `expires_at < NOW()`. A 24-hour expiration window is recommended for the parse-gate stage.

10. How should the tailoring quotas be implemented to handle lazy resets and high concurrency in MariaDB?

Recommendation: Use a `TailoringQuota` table with an atomic update strategy. Use a query like `UPDATE tailoring_quota SET count = 1, last_reset = CURRENT_DATE() WHERE user_id = ? AND last_reset < ?` to ensure resets happen only once per week per user without requiring a massive cron job.
</questions>

<answers>
1. Store steps as a `JSON` column. Use the `JSON_VALID()` constraint to ensure the stored text blocks or structured objects (e.g., `[{"text": "...", "order": 1}]`) maintain a valid format, allowing for schema-less expansion without losing validation.
2. Use a standard many-to-many relationship table. While MariaDB supports `JSON`, a relational table ensures better referential integrity and faster JOIN performance when filtering recipes based on user exclusions compared to searching inside a JSON blob.
3. The `Recipe` entity should have a copy of all fields of RecipeVersion.
4. Use MariaDB `FULLTEXT` indexes on denormalized search columns. Create a dedicated `search_text` column in the `Recipe` or `RecipeVersion` table that concatenates the title and ingredient names, and update it via Application-layer logic or triggers for P95 performance.
5. Use the `DECIMAL` (or `NUMERIC`) data type for quantities. Unlike `FLOAT` or `DOUBLE`, `DECIMAL` provides exact numeric representation, which is critical for scaling recipe ingredients and calculating calories without accumulating floating-point rounding errors.
6. Use a dedicated `substitutions` table. This allows for straightforward relational queries to track how often certain ingredients are swapped, which is more efficient for analytics than parsing JSON data across all versions.
7. Use a Symfony console command to perform range-based deletes. For very high volumes, consider MariaDB Table Partitioning by `RANGE` on the `created_at` timestamp to allow for near-instant cleanup of old data by dropping partitions.
8. Implement a dynamic registry where new ingredients are added as users enter them. Use a `is_verified` flag (TINYINT) to distinguish between user-generated content and normalized entries managed by the Unit Registry system.
9. Assign an `expires_at` (DATETIME) to these records. A scheduled Symfony command should run periodically to delete records where `expires_at < NOW()`. A 24-hour expiration window is recommended for the parse-gate stage.
10. Use a `TailoringQuota` table with an atomic update strategy. Use a query like `UPDATE tailoring_quota SET count = 1, last_reset = CURRENT_DATE() WHERE user_id = ? AND last_reset < ?` to ensure resets happen only once per week per user without requiring a massive cron job.
</answers>